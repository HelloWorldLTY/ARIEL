# Codes for paper: Performing Scientific Research with Artificial Intelligence Researcherü§î: A Comprehensive Study with Expert-Involved Evaluation

## Installation

To install the environment for querying LLM/LMM from API or Huggingface with local inference, please refer the yml file: **air.yml**. In short, installing [Huggingface](https://huggingface.co/) is enoughüòÑ.

To install the environment for evaluating the summary accuracy, please refer the yml file: **eval.yml**.

To finetune an LLM with LoRA, please refer the codes in [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory).


## Datasets

Please visit our [Huggingface page](https://huggingface.co/datasets/iLOVE2D/AIR_DATA) for the access of datasets.

## Running

For the experiments of long document summarization, please refer the folder **text_eval**.

For the experiments of scientific figure understanding, please refer the folder **image_eval**.

For the experiments of self-verification and self-correction, please refer the folder **self_improve**.


## Acknowledgement

We thanküôá‚Äç the developers of the following softwares (platforms), and without their help, we cannot successfully conduct our research:

[OpenAI](https://platform.openai.com/), [Google](https://ai.google.dev/gemma), [Meta](https://www.llama.com/), [Mistral AI](https://mistral.ai/), [Zhipu AI](https://huggingface.co/THUDM/glm-4-9b-chat-hf), [Anthropic](https://www.anthropic.com/), [Alibaba](https://huggingface.co/Qwen/Qwen-VL-Chat), [Microsoft](https://www.microsoft.com/en-us/research/project/llava-large-language-and-vision-assistant/), [Huggingface](https://huggingface.co/), and [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory).



## Citation